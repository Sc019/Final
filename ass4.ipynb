{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nvcc4jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Vector Additon\n",
    "\n",
    "%%cuda\n",
    "#include <stdio.h>\n",
    "\n",
    "#define N 10\n",
    "\n",
    "__global__ void vectorAdd(int *a, int *b, int *c) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (tid < N) {\n",
    "        c[tid] = a[tid] + b[tid];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int *a, *b, *c; // Host vectors\n",
    "    int *d_a, *d_b, *d_c; // Device vectors\n",
    "    int size = N * sizeof(int);\n",
    "\n",
    "    // Allocate memory for host vectors\n",
    "    a = (int*)malloc(size);\n",
    "    b = (int*)malloc(size);\n",
    "    c = (int*)malloc(size);\n",
    "\n",
    "    // Initialize host vectors\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        a[i] = i;\n",
    "        b[i] = i * i;\n",
    "    }\n",
    "\n",
    "    // Allocate memory for device vectors\n",
    "    cudaMalloc((void**)&d_a, size);\n",
    "    cudaMalloc((void**)&d_b, size);\n",
    "    cudaMalloc((void**)&d_c, size);\n",
    "\n",
    "    // Copy host vectors to device\n",
    "    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Launch kernel\n",
    "    vectorAdd<<<1, N>>>(d_a, d_b, d_c);\n",
    "\n",
    "    // Copy result from device to host\n",
    "    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Display result\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        printf(\"%d + %d = %d\\n\", a[i], b[i], c[i]);\n",
    "    }\n",
    "\n",
    "    // Free device memory\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "\n",
    "    // Free host memory\n",
    "    free(a);\n",
    "    free(b);\n",
    "    free(c);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cuda\n",
    "#include <stdio.h>\n",
    "\n",
    "#define N 4\n",
    "\n",
    "// Function to print a matrix\n",
    "void printMatrix(int *matrix, int width) {\n",
    "    for (int i = 0; i < width; ++i) {\n",
    "        for (int j = 0; j < width; ++j) {\n",
    "            printf(\"%d \", matrix[i * width + j]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void matrixMul(int *a, int *b, int *c, int width) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int sum = 0;\n",
    "\n",
    "    if (col < width && row < width) {\n",
    "        for (int i = 0; i < width; ++i) {\n",
    "            sum += a[row * width + i] * b[i * width + col];\n",
    "        }\n",
    "        c[row * width + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int *a, *b, *c; // Host matrices\n",
    "    int *d_a, *d_b, *d_c; // Device matrices\n",
    "    int size = N * N * sizeof(int);\n",
    "\n",
    "    // Allocate memory for host matrices\n",
    "    a = (int*)malloc(size);\n",
    "    b = (int*)malloc(size);\n",
    "    c = (int*)malloc(size);\n",
    "\n",
    "    // Initialize host matrices\n",
    "    for (int i = 0; i < N * N; i++) {\n",
    "        a[i] = i;\n",
    "        b[i] = i;\n",
    "    }\n",
    "\n",
    "    // Print matrices A and B\n",
    "    printf(\"Matrix A:\\n\");\n",
    "    printMatrix(a, N);\n",
    "    printf(\"\\nMatrix B:\\n\");\n",
    "    printMatrix(b, N);\n",
    "    printf(\"\\n\");\n",
    "\n",
    "    // Allocate memory for device matrices\n",
    "    cudaMalloc((void**)&d_a, size);\n",
    "    cudaMalloc((void**)&d_b, size);\n",
    "    cudaMalloc((void**)&d_c, size);\n",
    "\n",
    "    // Copy host matrices to device\n",
    "    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Define grid and block dimensions\n",
    "    dim3 dimBlock(4, 4);\n",
    "    dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x, (N + dimBlock.y - 1) / dimBlock.y);\n",
    "\n",
    "    // Launch kernel\n",
    "    matrixMul<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, N);\n",
    "\n",
    "    // Copy result from device to host\n",
    "    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Display result\n",
    "    printf(\"Matrix C:\\n\");\n",
    "    for (int i = 0; i < N * N; i++) {\n",
    "        printf(\"%d \", c[i]);\n",
    "        if ((i + 1) % N == 0) {\n",
    "            printf(\"\\n\");\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Free device memory\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "\n",
    "    // Free host memory\n",
    "    free(a);\n",
    "    free(b);\n",
    "    free(c);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
